dataset_config:
  vqa2_extended:
    add_multiple_choice: false
    use_images: false
    use_features: true
    zoo_requirements:
    - coco.defaults
    - coco.resnet152
    - vqa2.defaults
    features:
      train:
      - coco/defaults/features/trainval2014.lmdb,coco/resnet152/features/trainval2014.lmdb
      val:
      - coco/defaults/features/trainval2014.lmdb,coco/resnet152/features/trainval2014.lmdb
      test:
      - coco/defaults/features/trainval2014.lmdb,coco/resnet152/features/trainval2014.lmdb
    annotations:
      train:
      - vqa2/reliable_vqa/annotations/imdb_val2014-dev.npy
      val:
      - vqa2/reliable_vqa/annotations/imdb_val2014-val.npy
      test:
      - vqa2/reliable_vqa/annotations/imdb_val2014-test.npy

model_config:
  select_pythia:
    model_data_dir: ${env.data_dir}
    losses:
    - type: correct_pred
      params:
        target_type: regress_bce
        acc_threshold: 1.0
    classifier:
      type: logit
      params:
        img_hidden_dim: 5000
        text_hidden_dim: 300
    image_feature_embeddings:
    - modal_combine:
        type: non_linear_element_multiply
        params:
          dropout: 0
          hidden_dim: 5000
      normalization: softmax
      transform:
        type: linear
        params:
          out_dim: 1
    image_feature_dim: 2048
    image_feature_encodings:
    - type: finetune_faster_rcnn_fpn_fc7
      params:
        bias_file: models/detectron.defaults/fc7_b.pkl
        weights_file: models/detectron.defaults/fc7_w.pkl
        model_data_dir: ${model_config.select_pythia.model_data_dir}
    - type: default
      params:
        model_data_dir: ${model_config.select_pythia.model_data_dir}
    image_text_modal_combine:
      type: non_linear_element_multiply
      params:
        dropout: 0
        hidden_dim: 5000
    text_embeddings:
    - type: attention
      params:
        hidden_dim: 1024
        num_layers: 1
        conv1_out: 512
        conv2_out: 2
        dropout: 0
        embedding_dim: 300
        kernel_size: 1
        padding: 0
        model_data_dir: ${model_config.select_pythia.model_data_dir}
    selector:
      type: combo_embeddings_logit
      params:
        use_softmax: false
        answer_hidden_size: 1024
        hidden_1: 1024
        hidden_2: 1024
        dropout: 0.5
        top_k: 5
        full_dist: true
        use_qi_embed: true
        image_feat_size: 4096  # 2 * model_config.select_pythia.image_feature_dim}
        text_feat_size: 2048  # 2 * model_config.select_pythia.text_embeddings[0].params.hidden_dim
        qi_feat_size: ${model_config.select_pythia.image_text_modal_combine.params.hidden_dim}
        image_hidden_size: 512
        text_hidden_size: 512
        qi_hidden_size: 512
        pool_image_embedding: false
        pool_image_dim: 1
        pool_text_embedding: false
        pool_text_dim: 1
        pool_type: max
      sel_lr: 0.0001
    freeze_vqa: true

optimizer:
  type: adam_w
  params:
    lr: 0.0001
    eps: 1e-8

evaluation:
  reporter:
    type: file
    params:
      candidate_fields:
      - id
      - question_id
      - image_id
      - context_tokens
      - captions
      - scores
      - answers_indices
      - confidences
  metrics:
  - vqa_accuracy
  - type: risk_coverage
    key: risk_coverage
    datasets:
    - vqa2_extended
    params:
      save_dir: ${env:MMF_SAVE_DIR, ./save}
      precomputed_threshold_file: null
      risk_tolerances:
      - 0.01
      - 0.05
      - 0.1
      - 0.2
  - type: effective_reliability
    key: effective_reliability
    datasets:
    - vqa2_extended
    params:
      save_dir: ${env:MMF_SAVE_DIR, ./save}
      precomputed_cost_threshold_file: null
      cost_values:
      - 1
      - 10
      - 100

training:
  clip_norm_mode: all
  clip_gradients: true
  lr_ratio: 0.1
  lr_scheduler: true
  lr_steps:
  - 1500
  - 2000
  - 2500
  - 3000
  max_grad_l2_norm: 0.25
  max_updates: 3500
  use_warmup: false
  warmup_factor: 0.2
  warmup_iterations: 1000
  batch_size: 256
  num_workers: 7
  task_size_proportional_sampling: true
  early_stop:
    criteria: vqa2_extended/risk_coverage/auc
    minimize: true
  checkpoint_interval: 100
  evaluation_interval: 100
  log_interval: 10

checkpoint:
  pretrained_state_mapping:
    word_embedding: word_embedding
    text_embeddings: text_embeddings
    image_feature_encoders: image_feature_encoders
    image_feature_embeddings_list: image_feature_embeddings_list
    image_text_multi_modal_combine_layer: image_text_multi_modal_combine_layer
    classifier: classifier
    selector: selector
